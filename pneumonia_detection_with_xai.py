# -*- coding: utf-8 -*-
"""Pneumonia_Detection_with_xAI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cVzH_bPYFwt2YNZ7yogeP_NxMzWwqJ4C

Importing the necessary libraries:
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
from PIL import Image
import pandas as pd
import os
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.utils import class_weight
from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score
import matplotlib.pyplot as plt
import torch.nn.functional as F
import shap
from google.colab import drive

"""Downloading the zip file from the drive, unzipping it and uploading it to colab:"""

drive.mount('/content/drive')

train_zip_path = "/content/drive/MyDrive/balanced_train_images_subset.zip"
train_extract_dir = "/content/train"

valid_zip_path = "/content/drive/MyDrive/valid.zip"
valid_extract_dir = "/content/valid"


os.makedirs(train_extract_dir, exist_ok=True)
!unzip -q "{train_zip_path}" -d "{train_extract_dir}"
print("Unzipped train files into:", train_extract_dir)


os.makedirs(valid_extract_dir, exist_ok=True)
!unzip -q "{valid_zip_path}" -d "{valid_extract_dir}"
print("Unzipped valid files into:", valid_extract_dir)

FILTERED_IMAGES_PATH = "/content/train/train/"
VALID_IMAGES_PATH = "/content/valid/valid/"

# Path to the balanced training CSV
TRAIN_CSV_PATH = "/content/drive/MyDrive/balanced_pneumonia_train_subset_filtered_paths.csv"
# Path to the processed validation CSV
VALID_CSV_PATH = "/content/drive/MyDrive/processed_valid.csv"

"""To ensure reproducibility:"""

torch.manual_seed(22)
np.random.seed(22)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(22)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

#Image Dimensions set to 320x320
IMG_HEIGHT = 320
IMG_WIDTH = 320

#Training Parameters
BATCH_SIZE = 32
LEARNING_RATE = 1e-3
EPOCHS = 50
RANDOM_STATE = 22 #for reproducibility
NEW_TEST_SET_SIZE = 0.2 #test data size for split

"""Image Transformations:

Data Augmentation will be applied only to the training dataset to capture different aspects of the image when it is rotated, flipped, resized, changing brightness and contrast etc.

Data Augmentation will not be applied to the validation and test datasets.
"""

# Resize images to a fixed size
# Randomly rotate by a small degree
# Randomly change brightness and contrast
# Using ImageNet stats to normalize pixel values using mean and std deviation
train_transforms = transforms.Compose([
    transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),
    transforms.RandomRotation(5),
    transforms.RandomHorizontalFlip(),
    transforms.ColorJitter(brightness=0.1, contrast=0.1),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])


val_test_transforms = transforms.Compose([
    transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

"""Custom PyTorch Dataset to load data"""

class CheXpertDataset(Dataset):
  def __init__(self, dataframe, images_base_drive_dir, transform=None, data_type='valid'):
    """
    Args:
        dataframe: DataFrame with data.
        images_base_drive_dir: Base directory where images for this split are located.
        transform: transform to be applied on a sample.
    """
    self.dataframe = dataframe.reset_index(drop=True)
    self.images_base_drive_dir = images_base_drive_dir
    self.transform = transform
    self.data_type = data_type

    # Ensure necessary columns exist
    if 'Path' not in self.dataframe.columns:
        raise ValueError("DataFrame must contain a 'Path' column.")
    if 'Pneumonia_Binary' not in self.dataframe.columns:
        raise ValueError("DataFrame must contain a 'Pneumonia_Binary' column with binary labels.")
    if 'Age' not in self.dataframe.columns or 'Sex' not in self.dataframe.columns or 'AP/PA' not in self.dataframe.columns:
        print("Warning: Metadata columns (Age, Sex, AP/PA) not found in dataframe.")
        self.has_metadata = False
    else:
        self.has_metadata = True

  def __len__(self):
    return len(self.dataframe)

  def __getitem__(self, idx):
    if torch.is_tensor(idx):
        idx = idx.tolist()

    #Get the original relative path from the DataFrame's 'Path' column
    relative_path_from_csv = self.dataframe.iloc[idx]['Path']
    label = self.dataframe.iloc[idx]['Pneumonia_Binary']

    #Reconstruct the absolute image path
    path_parts = relative_path_from_csv.split('/')

    if self.data_type != 'valid':
      if len(path_parts) > 1:
        img_path = os.path.join(self.images_base_drive_dir, *path_parts[2:])
      else:
        print(f"Warning: Unexpected path format in CSV Path column at index {idx}: {relative_path_from_csv}. Cannot reconstruct path.")
        return None, None, None
    else:
      if len(path_parts) > 1:
        img_path = os.path.join(self.images_base_drive_dir, *path_parts[1:])
      else:
        print(f"Warning: Unexpected path format in CSV Path column at index {idx}: {relative_path_from_csv}. Cannot reconstruct path.")
        return None, None, None

    #Load image
    try:
      image = Image.open(img_path).convert('RGB')
    except FileNotFoundError:
      print(f"Error: Image file not found at {img_path}. Skipping sample {idx}.")
      return None, None, None
    except Exception as e:
        print(f"Error loading image file {img_path} at index {idx}: {e}. Skipping sample.")
        return None, None, None

    #Apply transformations
    if self.transform:
      image = self.transform(image)

    if self.has_metadata:
      metadata = self.dataframe.iloc[idx][['Age', 'Sex', 'AP/PA']]
      return image, torch.tensor(label, dtype=torch.float32), metadata
    else:
      return image, torch.tensor(label, dtype=torch.float32), None

def custom_collate_fn(batch):
  """
  This function filters out None samples.
  """
  batch = [item for item in batch if item is not None and item[0] is not None]
  if not batch:
      return None, None, None

  #Separates images, labels, and metadata
  images = torch.stack([item[0] for item in batch])
  labels = torch.stack([item[1] for item in batch])
  #Collects metadata into a list of pandas Series or None
  metadata_list = [item[2] for item in batch]

  if metadata_list and metadata_list[0] is not None:
      metadata_batch_df = pd.DataFrame(metadata_list).reset_index(drop=True)
  else:
      metadata_batch_df = None


  return images, labels, metadata_batch_df

"""Spatial Attention Mechanism:

This module will learn to weigh different spatial locations in the feature maps

"""

class SpatialAttention(nn.Module):
  def __init__(self, in_channels):
    super(SpatialAttention, self).__init__()
    # A simple attention mechanism that uses a convolutional layer to predict attention scores
    self.conv = nn.Conv2d(in_channels, 1, kernel_size=1)
    # Sigmoid is used to get attention weights between 0 and 1
    self.sigmoid = nn.Sigmoid()

  def forward(self, x):
    attention_scores = self.conv(x)
    attention_weights = self.sigmoid(attention_scores)
    # Apply attention: multiply input feature maps by attention weights
    attended_features = x * attention_weights

    return attended_features, attention_weights

"""Define the Custom CNN Model with Integrated Attention:"""

class CustomCheXpertCNNMultimodal(nn.Module):
  def __init__(self):
    super(CustomCheXpertCNNMultimodal, self).__init__()
    # Defining CNN blocks
    # Block 1: (Input 3 channels for RGB)
    # padding=1 for same padding, kernel_size=3
    # stride=2 for typical pooling
    self.block1 = nn.Sequential(
        nn.Conv2d(3, 32, kernel_size=3, padding=1),
        nn.BatchNorm2d(32),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2, stride=2),
        nn.Dropout(0.10)
    )

    self.block2 = nn.Sequential(
        nn.Conv2d(32, 64, kernel_size=3, padding=1),
        nn.BatchNorm2d(64),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2, stride=2),
        nn.Dropout(0.10)
    )

    self.block3 = nn.Sequential(
        nn.Conv2d(64, 128, kernel_size=3, padding=1),
        nn.BatchNorm2d(128),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2, stride=2),
        nn.Dropout(0.10)
    )

    self.block4 = nn.Sequential(
        nn.Conv2d(128, 256, kernel_size=3, padding=1),
        nn.BatchNorm2d(256),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2, stride=2),
        nn.Dropout(0.10)
    )

    #The input channels to Attention should match the output channels of the previous block
    self.attention = SpatialAttention(in_channels=256)

    # Define the Metadata Branch
    metadata_input_size = 5
    metadata_hidden_size = 16

    self.metadata_branch = nn.Sequential(
        nn.Linear(metadata_input_size, metadata_hidden_size),
        nn.BatchNorm1d(metadata_hidden_size),
        nn.ReLU(),
        nn.Dropout(0.20)
    )

    # Classification head
    # Channels * Height * Width
    flattened_image_size = 256 * 20 * 20

    # Define the Fusion and Classifier Head
    # Input size is flattened image size + metadata hidden size
    fused_input_size = flattened_image_size + metadata_hidden_size
    classifier_hidden_size = 512

    # Flatten the feature maps into a vector
    # First Dense (Linear) layer
    # Use BatchNorm1d after a Linear layer
    # Final Dense (Linear) layer for binary classification output (logits)
    self.classifier = nn.Sequential(
        nn.Linear(fused_input_size, classifier_hidden_size),
        nn.BatchNorm1d(classifier_hidden_size),
        nn.ReLU(),
        nn.Dropout(0.30),
        nn.Linear(classifier_hidden_size, 1)
    )

  def forward(self, img_input, metadata_input_df):
    # Process Image Input
    img_features = self.block1(img_input)
    img_features = self.block2(img_features)
    img_features = self.block3(img_features)
    img_features = self.block4(img_features)
    attended_img_features, attention_weights = self.attention(img_features)

    # Flatten image features
    flattened_img_features = attended_img_features.view(attended_img_features.size(0), -1)

    # Process Metadata Input
    if metadata_input_df is not None:
        metadata_encoded = pd.get_dummies(metadata_input_df, columns=['Sex', 'AP/PA'], drop_first=False, dtype=np.float32)

        encoded_feature_names = ['Age', 'Sex_Female', 'Sex_Male', 'ViewPosition_AP', 'ViewPosition_PA']

        for col in encoded_feature_names:
            if col not in metadata_encoded.columns:
                metadata_encoded[col] = 0.0

        #Reorder columns to match the expected input order
        try:
            metadata_encoded = metadata_encoded[encoded_feature_names]
        except KeyError as e:
            print(f"Error: Missing expected encoded column during metadata processing: {e}")
            return None, None

        metadata_tensor = torch.tensor(metadata_encoded.values, dtype=torch.float32).to(device)
        metadata_features = self.metadata_branch(metadata_tensor)
    else:
        print("Warning: Metadata input is None for a batch.")
        return None, None

    #Fuse Image and Metadata Features
    fused_features = torch.cat([flattened_img_features, metadata_features], dim=1)

    #Pass through the Classifier Head
    logits = self.classifier(fused_features)

    return logits, attention_weights

"""Setting up Data Loaders:"""

print("Setting up Data Splitting and DataLoaders...")

train_df_balanced = pd.read_csv(TRAIN_CSV_PATH)

new_train_df, new_test_df = train_test_split(
    train_df_balanced,
    test_size=NEW_TEST_SET_SIZE,
    random_state=RANDOM_STATE,
    stratify=train_df_balanced['Pneumonia_Binary']
)

val_df = pd.read_csv(VALID_CSV_PATH)

#Create Dataset instances
train_dataset = CheXpertDataset(dataframe=new_train_df, images_base_drive_dir=FILTERED_IMAGES_PATH, transform=train_transforms, data_type='train')
val_dataset = CheXpertDataset(dataframe=val_df, images_base_drive_dir=VALID_IMAGES_PATH, transform=val_test_transforms, data_type='valid')
new_test_dataset = CheXpertDataset(dataframe=new_test_df, images_base_drive_dir=FILTERED_IMAGES_PATH, transform=val_test_transforms, data_type='train')


#Create DataLoader instances
train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True, collate_fn=custom_collate_fn)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True, collate_fn=custom_collate_fn)
new_test_loader = DataLoader(new_test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True, collate_fn=custom_collate_fn)


print(f"\nDataLoaders created:")
print(f"  New Train dataset size: {len(train_dataset)}")
print(f"  Validation dataset size: {len(val_dataset)}")
print(f"  New Test dataset size: {len(new_test_dataset)}")
print(f"  New Train batches per epoch: {len(train_loader)}")
print(f"  Validation batches per epoch: {len(val_loader)}")
print(f"  New Test batches for final evaluation: {len(new_test_loader)}")
print("-" * 30)

"""Set up Model, Loss Function, Optimizer, and Device:"""

print("Setting up Model, Loss Function, Optimizer, and Device...")
#Initialize the model
model = CustomCheXpertCNNMultimodal()
#Move model to GPU if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")
model.to(device)

#Define the loss function
#Calculate class weights for the BALANCED training set
y_train_binary = train_dataset.dataframe['Pneumonia_Binary'].values
classes = np.unique(y_train_binary)
if 0 not in classes: classes = np.append(classes, 0)
if 1 not in classes: classes = np.append(classes, 1)
classes.sort()

class_weights_array = class_weight.compute_class_weight(
    'balanced',
    classes=classes,
    y=y_train_binary
)

balanced_pos_weight = class_weights_array[1]
factor = 0.7
final_pos_weight = balanced_pos_weight * factor

criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(final_pos_weight, device=device))

print(f"Calculated balanced pos_weight: {balanced_pos_weight:.4f}")
print(f"Using final pos_weight: {final_pos_weight:.4f}")

#Define the optimizer
optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)

#Learning Rate Scheduler
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=1)

print("Setup complete.")
print("-" * 30)

"""Training and validation:"""

print("\nStarting training...")

#Lists to store training and validation metrics history
train_accuracy_history = []
train_loss_history = []
val_loss_history = []
val_accuracy_history = []
val_auc_history = []
val_precision_history = []
val_recall_history = []

#Early Stopping parameters
best_val_loss = float('inf')
patience_counter = 0
#Number of epochs to wait for improvement before stopping
EARLY_STOPPING_PATIENCE = 10

#Path to save the best model
CHECKPOINT_PATH = os.path.join("/content/drive/MyDrive/processed_data", "best_cnn_multimodal_final.pth")

#Create directory if it does not exist
os.makedirs(os.path.dirname(CHECKPOINT_PATH), exist_ok=True)

#Training
for epoch in range(EPOCHS):
  model.train()
  running_train_loss = 0.0
  correct_train_preds = 0
  total_train_samples = 0

  for i, (inputs, labels, metadata) in enumerate(train_loader):
    if inputs is None or metadata is None:
        print(f"Warning: Skipping empty batch in training epoch {epoch+1}.")
        continue

    inputs, labels = inputs.to(device), labels.to(device)

    #Zero the parameter gradients
    optimizer.zero_grad()

    # Get logits and attention weights from the model
    logits, attention_weights = model(inputs, metadata)
    labels = labels.unsqueeze(1)

    # Calculate loss
    loss = criterion(logits, labels)

    # Backward pass and optimize
    loss.backward()
    optimizer.step()

    running_train_loss += loss.item() * inputs.size(0)
    total_train_samples += inputs.size(0)

    train_probs = torch.sigmoid(logits)
    train_binary_preds = (train_probs > 0.5).float()
    correct_train_preds += (train_binary_preds == labels).sum().item()

  epoch_train_loss = running_train_loss / len(train_dataset)
  train_loss_history.append(epoch_train_loss)

  #Validation
  model.eval()
  running_val_loss = 0.0
  all_val_labels = []
  all_val_preds_logits = []

  with torch.no_grad():
    for i, (inputs, labels, metadata) in enumerate(val_loader):
        if inputs is None or metadata is None:
            print(f"Warning: Skipping empty batch in validation epoch {epoch+1}.")
            continue

        inputs, labels = inputs.to(device), labels.to(device)

        logits, attention_weights = model(inputs, metadata)
        labels = labels.unsqueeze(1)

        loss = criterion(logits, labels)

        running_val_loss += loss.item() * inputs.size(0)

        all_val_labels.extend(labels.cpu().numpy())
        all_val_preds_logits.extend(logits.cpu().numpy())

  epoch_val_loss = running_val_loss / len(val_dataset)
  val_loss_history.append(epoch_val_loss)

  #Calculate validation metrics
  all_val_probs = torch.sigmoid(torch.tensor(all_val_preds_logits)).numpy()
  all_val_binary_preds = (all_val_probs > 0.5).astype(float)
  val_accuracy = accuracy_score(all_val_labels, all_val_binary_preds)
  val_precision = precision_score(all_val_labels, all_val_binary_preds, zero_division=0)
  val_recall = recall_score(all_val_labels, all_val_binary_preds, zero_division=0)

  if len(np.unique(all_val_labels)) > 1:
      val_auc = roc_auc_score(all_val_labels, all_val_probs)
  else:
      val_auc = float('nan')


  val_accuracy_history.append(val_accuracy)
  val_precision_history.append(val_precision)
  val_recall_history.append(val_recall)
  val_auc_history.append(val_auc)

  print(f"Epoch {epoch+1}/{EPOCHS} - Train Loss: {epoch_train_loss:.4f} - Val Loss: {epoch_val_loss:.4f} - Val Acc: {val_accuracy:.4f} - Val AUC: {val_auc:.4f} - Val Prec: {val_precision:.4f} - Val Rec: {val_recall:.4f}")

  #Learning Rate Scheduler Step
  scheduler.step(epoch_val_loss)

  #Early Stopping
  if epoch_val_loss < best_val_loss:
      best_val_loss = epoch_val_loss
      patience_counter = 0
      # Save the model weights if validation loss improved
      print("Validation loss improved. Saving model checkpoint...")
      torch.save(model.state_dict(), CHECKPOINT_PATH)
  else:
      patience_counter += 1
      print(f"Validation loss did not improve. Patience counter: {patience_counter}/{EARLY_STOPPING_PATIENCE}")
      if patience_counter >= EARLY_STOPPING_PATIENCE:
          print(f"Early stopping triggered after {epoch+1} epochs.")
          break

print("\nTraining finished.")
print(f"Best model checkpoint saved to: {CHECKPOINT_PATH}")
print("-" * 30)

"""Load the best model and evaluate on test dataset:"""

print("\nLoading best model checkpoint and evaluating on test set...")
# Initialize a new model instance with the same architecture
best_model = CustomCheXpertCNNMultimodal()
# Load the saved state dictionary
try:
  best_model.to(device)
  best_model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=device))
  print("Successfully loaded best model weights.")
except FileNotFoundError:
  print(f"Error: Best model checkpoint not found at {CHECKPOINT_PATH}. Cannot evaluate test set.")
  best_model = None

if best_model:
  best_model.eval()

  all_test_labels = []
  all_test_preds_logits = []

  with torch.no_grad():
    for inputs, labels, metadata in new_test_loader:
      if inputs is None or metadata is None:
        print(f"Warning: Skipping empty batch during test evaluation.")
        continue

      inputs, labels = inputs.to(device), labels.to(device)
      logits, attention_weights = best_model(inputs, metadata)

      all_test_labels.extend(labels.cpu().numpy())
      all_test_preds_logits.extend(logits.cpu().numpy())

    # Calculate test metrics
    all_test_probs = torch.sigmoid(torch.tensor(all_test_preds_logits)).numpy()
    all_test_binary_preds = (all_test_probs > 0.5).astype(float)

    test_accuracy = accuracy_score(all_test_labels, all_test_binary_preds)
    test_precision = precision_score(all_test_labels, all_test_binary_preds, zero_division=0)
    test_recall = recall_score(all_test_labels, all_test_binary_preds, zero_division=0)

    if len(np.unique(all_test_labels)) > 1:
        test_auc = roc_auc_score(all_test_labels, all_test_probs)
    else:
        test_auc = float('nan')


    print("\n--- Test Set Evaluation ---")
    print(f"Test Accuracy: {test_accuracy:.4f}")
    print(f"Test Precision: {test_precision:.4f}")
    print(f"Test Recall: {test_recall:.4f}")
    print(f"Test AUC: {test_auc:.4f}")
    print("-" * 30)

"""Visualisations:"""

epochs = range(1, len(train_loss_history) + 1)

# Plot Loss
plt.figure(figsize=(10, 6))
plt.plot(epochs, train_loss_history, 'bo-', label='Training loss')
plt.plot(epochs, val_loss_history, 'ro-', label='Validation loss')
plt.title('Training and Validation Loss per Epoch')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)
plt.show()


plt.figure(figsize=(12, 8))

# Plot Validation Accuracy
plt.subplot(2, 2, 1) # 2 rows, 2 columns, 1st plot
plt.plot(epochs, val_accuracy_history, 'go-', label='Validation Accuracy')
plt.title('Validation Accuracy per Epoch')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)

# Plot Validation AUC
plt.subplot(2, 2, 2)
plt.plot(epochs, val_auc_history, 'co-', label='Validation AUC')
plt.title('Validation AUC per Epoch')
plt.xlabel('Epochs')
plt.ylabel('AUC')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()

"""Attention HeatMap:"""

if 'best_model' in locals() and best_model is not None:
  correctly_predicted_index = None
  search_limit = 100
  for idx in range(min(len(new_test_dataset), search_limit)):
      try:
          image_tensor, true_label_tensor, metadata_series = new_test_dataset[idx]
          true_label = true_label_tensor.item()

          image_tensor_batch = image_tensor.unsqueeze(0).to(device)
          metadata_df_batch = pd.DataFrame([metadata_series])

          best_model.eval()
          with torch.no_grad():
            logits, _ = best_model(image_tensor_batch, metadata_df_batch)

          predicted_prob = torch.sigmoid(logits).item()
          predicted_class = 1 if predicted_prob > 0.5 else 0

          if predicted_class == int(true_label):
            correctly_predicted_index = idx
            break

      except Exception as e:
        print(f"Error processing sample")
        continue

  if correctly_predicted_index is not None:
      image_index_to_explain = correctly_predicted_index
      image_tensor, true_label_tensor, metadata_series = new_test_dataset[image_index_to_explain]
      true_label = true_label_tensor.item()
      relative_path_from_csv = new_test_dataset.dataframe.iloc[image_index_to_explain]['Path']
      images_base_drive_dir = new_test_dataset.images_base_drive_dir
      path_parts = relative_path_from_csv.split('/')

      original_image_path_colab = None
      if len(path_parts) > 1:
        original_image_path_colab = os.path.join(images_base_drive_dir, *path_parts[2:])
      else:
        print(f"Cannot reconstruct original image path for visualization.")
        original_image = None

      original_image = None
      if original_image_path_colab:
          try:
            original_image = Image.open(original_image_path_colab).convert('RGB')
            print(f"Loaded original image from: {original_image_path_colab}")
          except FileNotFoundError:
            print(f"Cannot load original image for overlay.")
            original_image = None
          except Exception as e:
            print(f"Cannot load original image for overlay.")
            original_image = None

      image_tensor_batch = image_tensor.unsqueeze(0).to(device)
      metadata_df_batch = pd.DataFrame([metadata_series])

      best_model.eval()
      with torch.no_grad():
        logits, attention_weights = best_model(image_tensor_batch, metadata_df_batch)

      attention_weights_np = attention_weights.squeeze(0).cpu().numpy()

      if attention_weights_np.ndim == 3 and attention_weights_np.shape[0] == 1:
        attention_weights_np = attention_weights_np.squeeze(0)

      if original_image:
        heatmap_pil = Image.fromarray(np.uint8(255 * attention_weights_np))
        heatmap_resized = heatmap_pil.resize(original_image.size, Image.BILINEAR)
        heatmap_resized_np = np.array(heatmap_resized)

        # Visualize Original Image + Attention Heatmap Overlay
        plt.figure(figsize=(10, 5))
        plt.subplot(1, 2, 1)
        plt.imshow(original_image, cmap='gray')
        plt.title(f"Original Image\nTrue: {true_label}, Pred: {predicted_class} ({predicted_prob:.2f})")
        plt.axis('off')

        plt.subplot(1, 2, 2)
        plt.imshow(original_image, cmap='gray')
        plt.imshow(heatmap_resized_np, cmap='jet', alpha=0.5)
        plt.title("Spatial Attention Heatmap Overlay")
        plt.axis('off')
        plt.colorbar(label='Attention Weight', orientation='horizontal')

        plt.tight_layout()
        plt.show()
      else:
          print("Original image could not be loaded.")

